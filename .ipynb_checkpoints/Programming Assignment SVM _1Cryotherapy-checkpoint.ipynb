{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment : SVM\n",
    "In this programming assignment, you would use Support Vector Machines and Logistic Regression\n",
    "for classification problem. We are using Logistic Regression to compare performance of both the algorithms on the same dataset with different values of parameters like type of kernel used, type of regularization techniques used (ridge/lasso) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the assignment carefully, by understanding the structure of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions :\n",
    "You have to write a small report in a pdf file. You can use bullet points to discuss your results for every function of the assignment.<br>\n",
    "For example, for data1.csv dataset, write which method gave you the best accuracy using which value of the parameter.<br>\n",
    "Do not write explainations, just discuss your results / observations point to point. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries to be used:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset:\n",
    "The dataset we are using for this assignment is taken from UCI Machine Learning Repository. The dataset consists of Attributes/Factors that contribute to prediction of Diabetic Retinopathy(DR) in a diabetic patient. Given some predictors, we need to predict the value of target variable i.e. DR or Non-DR case. The dataset is given in the file data1.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file into a pandas data frame.\n",
    "df = pd.read_csv('Cryotherapy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There can be some columns which may have missing values. So, we are removing those columns from our dataset.\n",
    "df1 = df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the df1 data frame into a numpy array named df2. Use values method of dataframes.\n",
    "df2 = df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows and first 19 columns as X from df2.\n",
    "X = df2[:,0:6]\n",
    "# Select all rows and last column as Y from df2.\n",
    "Y = df2[:,df2.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test data.\n",
    "# Select first 600 rows as training dataset and the remaining rows as test dataset.\n",
    "X_train = X[0:45]\n",
    "Y_train = Y[0:45]\n",
    "X_test = X[45:90]\n",
    "Y_test = Y[45:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "First we will fit the dataset using a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Lasso(L1) Regularization.\n",
    "Read the comments in the below cell carefully.\n",
    "Try different values of parameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store values of training set accuracy.\n",
    "acc_train_logreg = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store values of test set accuracy.\n",
    "acc_test_logreg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store different values of parameter 'c'.\n",
    "c_logreg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function logreg that accepts 'c' as a parameter, which is used to create logreg model \n",
    "# with different values of C.\n",
    "def logreg_model(c , X_train, Y_train, X_test, Y_test):\n",
    "    # Create an object of logistic regression model using linear_model.\n",
    "    # Pass the value of penalty as 'L1'. By default, it is 'L2'.\n",
    "    # Pass the value of C = c. Note that C is the inverse of lambda. So, small value of C i.e. b/w 0 and 1 \n",
    "    # means stronger regularization and large value means less regularization.\n",
    "    # Also, in sklearn, L1 is only supported with solver = 'saga'. Solver is the type of optimization algorithm like GDA or\n",
    "    # SGDA, which is to be used. So, 'saga' is another algorithm like that. Pass the value of solver as 'saga'\n",
    "\n",
    "    logreg = linear_model.LogisticRegression('l1',C = c,solver='saga')\n",
    "    \n",
    "    # Fit the model on the training set.\n",
    "    logreg.fit(X_train,Y_train)\n",
    "    \n",
    "    # Find the prediction on training set.\n",
    "    Yhat_train = logreg.predict(X_train)\n",
    "    acc_train = np.mean(Yhat_train == Y_train)\n",
    "    acc_train_logreg.append(acc_train)\n",
    "    print(\"Accuracy on training data = %f\" % acc_train)\n",
    "    \n",
    "    # Find the prediction on test set.\n",
    "    Yhat_test = logreg.predict(X_test)\n",
    "    acc_test = np.mean(Yhat_test == Y_test)\n",
    "    acc_test_logreg.append(acc_test)\n",
    "    print(\"Accuracy on test data = %f\" % acc_test)\n",
    "    \n",
    "    c_logreg.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.488889\n",
      "Accuracy on test data = 0.577778\n",
      "Accuracy on training data = 0.511111\n",
      "Accuracy on test data = 0.422222\n",
      "Accuracy on training data = 0.511111\n",
      "Accuracy on test data = 0.422222\n",
      "Accuracy on training data = 0.511111\n",
      "Accuracy on test data = 0.422222\n",
      "Accuracy on training data = 0.511111\n",
      "Accuracy on test data = 0.422222\n",
      "Accuracy on training data = 0.511111\n",
      "Accuracy on test data = 0.422222\n",
      "Accuracy on training data = 0.511111\n",
      "Accuracy on test data = 0.422222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\heart\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\heart\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\heart\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\heart\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\heart\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbc10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the above function i.e. logreg_model with different values of parameter 'c'.\n",
    "# Start with smaller values of 'c' say 0.0001, 0.001, 0.01, 0.1, 1, 10, 100\n",
    "logreg_model(0.0001, X_train, Y_train, X_test, Y_test)\n",
    "logreg_model(0.001, X_train, Y_train, X_test, Y_test)\n",
    "logreg_model(0.01, X_train, Y_train, X_test, Y_test)\n",
    "logreg_model(0.1, X_train, Y_train, X_test, Y_test)\n",
    "logreg_model(1, X_train, Y_train, X_test, Y_test)\n",
    "logreg_model(10, X_train, Y_train, X_test, Y_test)\n",
    "logreg_model(100, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "# Write code to plot 2 plots.\n",
    "# Plot training accuracy(Y-axis) v/s 'c' on X - Axis.\n",
    "# Plot test accuracy(Y-Axis) v/s 'c' on X - Axis.\n",
    "plt.grid()\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('test acc vs c (blue) and training acc vs c(orange)')\n",
    "plt.scatter(c_logreg,acc_test_logreg)\n",
    "\n",
    "plt.grid()\n",
    "plt.scatter(c_logreg,acc_train_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Ridge(L2) Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store values of training set accuracy.\n",
    "acc_train_logreg2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store values of test set accuracy.\n",
    "acc_test_logreg2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store different values of parameter 'c'.\n",
    "c_logreg2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logreg2_model(c , X_train, Y_train, X_test, Y_test):\n",
    "    # Create an object of logistic regression model using linear_model.\n",
    "    # Pass the value of C=c.\n",
    "    # You need not pass other parameters as penalty is 'L2' by default.\n",
    "    \n",
    "    logreg2 = None\n",
    "    \n",
    "    # Fit the model on the training set.\n",
    "    None\n",
    "    \n",
    "    # Find the prediction on training set.\n",
    "    Yhat_train = None\n",
    "    acc_train = np.mean(Yhat_train == Y_train)\n",
    "    acc_train_logreg2.append(acc_train)\n",
    "    print(\"Accuracy on training data = %f\" % acc_train)\n",
    "    \n",
    "    # Find the prediction and accuracy on test set.\n",
    "    Yhat_test = None\n",
    "    acc_test = np.mean(Yhat_test == Y_test)\n",
    "    acc_test_logreg2.append(acc_test)\n",
    "    print(\"Accuracy on test data = %f\" % acc_test)\n",
    "    \n",
    "    c_logreg2.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the above function i.e. logreg2_model with different values of parameter 'c'.\n",
    "# Start with smaller values of 'c' say 0.0001, 0.001, 0.01, 0.1, 1, 10, 100\n",
    "None\n",
    "# Write code to plot 2 plots.\n",
    "# Plot training accuracy(Y-axis) v/s 'c' on X - Axis.\n",
    "# Plot test accuracy(Y-Axis) v/s 'c' on X - Axis.\n",
    "None \n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Using Polynomial Feature Transformation\n",
    "Refer the given link to know how we can transform features.<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an object of PolynomialFeatures(2):\n",
    "poly = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the transformed data matrices for training and test using poly.fit_transform(..)\n",
    "X_transformed_train = None\n",
    "X_transformed_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the shapes of the new matrices.\n",
    "# Originally, we had 19 features.\n",
    "X_transformed_train.shape\n",
    "X_transformed_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calling the logreg_model(..) using transformed features.\n",
    "# Pass c, X_transformed_train , Y_train, X_transformed_test, Y_test\n",
    "# Before calling the function, we need to re-initialize the 3 lists in which we append the \n",
    "# results (accuracy) because these lists are global variables.\n",
    "acc_train_logreg = []\n",
    "acc_test_logreg = []\n",
    "c_logreg = []\n",
    "# Call the function logreg_model.\n",
    "None\n",
    "# Write code to plot 2 plots.\n",
    "# Plot training accuracy(Y-axis) v/s 'c' on X - Axis.\n",
    "# Plot test accuracy(Y-Axis) v/s 'c' on X - Axis.\n",
    "None\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calling the logreg2_model(..) using transformed features.\n",
    "# Pass c, X_transformed_train , Y_train, X_transformed_test, Y_test\n",
    "# Before calling the function, we need to re-initialize the 3 lists in which we append the \n",
    "# results (accuracy) beacause these list are global varibles.\n",
    "acc_train_logreg2 = []\n",
    "acc_test_logreg2 = []\n",
    "c_logreg2 = []\n",
    "# Call the function logreg2_model.\n",
    "None\n",
    "# Write code to plot 2 plots.\n",
    "# Plot training accuracy(Y-axis) v/s 'c' on X - Axis.\n",
    "# Plot test accuracy(Y-Axis) v/s 'c' on X - Axis.\n",
    "None\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "<u>Do not</u> use these transformed features for the further part of the assignment. Use the X_train, Y_train, X_test and Y_test matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "Now we will use the same dataset and try to find a classifier using SVM.\n",
    "For more information about svm classifier, check the given link.\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Linear Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_train_svm_linear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_test_svm_linear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_svm_linear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete the function below:\n",
    "# In this function and next 2 functions, we are not passing the data matrices as parameters \n",
    "# because we can use global variables inside the functions.\n",
    "def svm_linear(c):\n",
    "    # Create an object of svm.SVC(probability = False, kernel = 'linear', C = c).\n",
    "    svc = None\n",
    "    \n",
    "    # Fit the classifier on the training set.\n",
    "    None\n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_svc_linear_train = None\n",
    "    acc_train = np.mean(Yhat_svc_linear_train == Y_train)\n",
    "    acc_train_svm_linear.append(acc_train)\n",
    "    print('Accuracy = {0:f}'.format(acc_train))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_svc_linear_test = None\n",
    "    acc_test = np.mean(Yhat_svc_linear_test == Y_test)\n",
    "    acc_test_svm_linear.append(acc_test)\n",
    "    print('Accuracy = {0:f}'.format(acc_test))\n",
    "    \n",
    "    c_svm_linear.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the above function i.e. svm_linear with different values of parameter 'c'.\n",
    "# Start with smaller values of 'c' say 0.0001, 0.001, 0.01, 0.1, 1, 10, 100\n",
    "None\n",
    "# Write code to plot 2 plots.\n",
    "# Plot training accuracy(Y-axis) v/s 'c' on X - Axis.\n",
    "# Plot test accuracy(Y-Axis) v/s 'c' on X - Axis.\n",
    "None \n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of parameter C above and see the difference in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Radial Basis Function(RBF) Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete the function below.\n",
    "# g is the value of gamma. \n",
    "def svm_rbf(c, g):\n",
    "    # Create an object of svm classifier using svm.SVC()\n",
    "    # Pass probability = False, kernel = 'rbf', value of C = c and rbf paramter gamma = g.\n",
    "    svc_rbf = None\n",
    "    \n",
    "    # Fit the classifier on the training set.\n",
    "    None\n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_svc_rbf_train = None\n",
    "    acc = np.mean(Yhat_svc_rbf_train == Y_train)\n",
    "    print('Accuracy = {0:f}'.format(acc))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_svc_rbf_test = None\n",
    "    acc = np.mean(Yhat_svc_rbf_test == Y_test)\n",
    "    print('Accuracy = {0:f}'.format(acc))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the above function i.e. svm_rbf with different values of parameter 'c' and 'g'.\n",
    "# Start with smaller values of 'c' say 0.0001, 0.001, 0.01, 0.1, 1, 10, 100\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of parameter C and gamma above and see the difference in the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Polynomial Kernel.\n",
    "Note: SVM with polynomial kernel can be sometimes very slow. If that is the case, use smaller size of training set. Instead of all 600 training examples, use less (say 300)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_train_svm_poly = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_test_svm_poly = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_svm_poly = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_polynomial(c):\n",
    "    # Create an object of svm classifier using svm.SVC()\n",
    "    # Pass probability = False, kernel = 'poly' , value of C = c.\n",
    "    svc_polynomial = None\n",
    "    \n",
    "    A = X_train[0:300,:]  # First 300 rows of training set.\n",
    "    B = Y_train[0:300]  \n",
    "    C = X_test[0:100,:]   # First 100 rows of test set.\n",
    "    D = Y_test[0:100]\n",
    "    \n",
    "    # Fit the classifier on the training set.\n",
    "    # Use A and B to train and C and D to test.\n",
    "    None\n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_svc_polynomial_train = None\n",
    "    acc_train = np.mean(Yhat_svc_polynomial_train == B)\n",
    "    acc_train_svm_poly.append(acc_train)\n",
    "    print('Accuracy = {0:f}'.format(acc_train))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_svc_polynomial_test = None\n",
    "    acc_test = np.mean(Yhat_svc_polynomial_test == D)\n",
    "    acc_test_svm_poly.append(acc_test)\n",
    "    print('Accuracy = {0:f}'.format(acc_test))\n",
    "    \n",
    "    c_svm_poly.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the above function i.e. svm_poly with different values of parameter 'c'.\n",
    "# Start with smaller values of 'c' say 0.0001, 0.001, 0.01, 0.1, 1, 10, 100\n",
    "None\n",
    "# Write code to plot 2 plots.\n",
    "# Plot training accuracy(Y-axis) v/s 'c' on X - Axis.\n",
    "# Plot test accuracy(Y-Axis) v/s 'c' on X - Axis.\n",
    "None \n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of parameter C and see the difference in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeating the Assignment with 2 more Datasets:\n",
    "1) Cryotherapy.csv (Predict result of treatment using 6 predictors).\n",
    "https://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+<br>\n",
    "2) Immunotherapy.csv (Predict result of treatment using 7 predictors).\n",
    "https://archive.ics.uci.edu/ml/datasets/Immunotherapy+Dataset <br>\n",
    "You have to repeat the full assignment with 2 more different datasets. You have to write a small report in a pdf file. You can use bullet points to discuss your results for every function of the assignment.<br>\n",
    "For example, for data1.csv dataset, write which method gave you the best accuracy using which value of the parameter.<br>\n",
    "You have to write this for all the 3 datasets in a single pdf file. \n",
    "Do not write explainations, just discuss your results / observations point to point. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
