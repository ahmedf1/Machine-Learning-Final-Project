{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Using Gradient Descent And Stochastic Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary modules (numpy, pandas, matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code cell using shift+enter before moving further\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets, linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the column names in a list and use pandas read_csv to extract the dataframe from the file. Print the dataframe and the columns list to ensure that the mapping and the data was read correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =['Algebra2/Trigonometry', \n",
    "        'English', 'Geometry', 'Global History and Geography','Integrated Algebra', \n",
    "        'Living Environment', 'Physical Settings/Chemistry', 'Physical Settings/Physics',\n",
    "        'Average SAT Score (Total)'\n",
    "]\n",
    "\n",
    "#Write your code below to save dataframe in the df variable below. \n",
    "# In place of None, write the pandas command to read the csv file.\n",
    "#df = pd.read_csv('HS_Regents_Sat_Scores_2015.csv',names=names)\n",
    "#print(df)\n",
    "#print(df.columns.tolist())\n",
    "#df = pd.read_csv('/Users/Farhad_Ahmed/Desktop/ML intros/ML Project/HS_Regents_Sat_Scores_2015.csv')\n",
    "df = pd.read_csv('HS_Regents_Sat_Scores_2015.csv')\n",
    "#print(df)\n",
    "#data = df.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must define which features of the dataframe we will use. Then extract these values from the dataframe and do some feature scaling if necessary. Fetch those columns of data into a smaller dataframe. Then filter out the rows that do not contain valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  52.6   71.9   66.4   61.    64.3   64.4   63.    64.7 1265. ]\n",
      " [  64.2   72.5   65.    66.9   63.5   70.8   65.7   71.5 1367. ]\n",
      " [  77.    74.    80.9   81.8   71.6   84.8   67.9   80.2 1700. ]\n",
      " [  81.2   88.2   84.2   90.9   88.2   90.7   83.1   79.9 1889. ]\n",
      " [  81.4   75.7   79.6   88.9   80.5   87.5   76.9   72.4 1704. ]\n",
      " [  64.    78.    72.1   72.6   72.6   73.2   73.1   74.1 1327. ]\n",
      " [  84.3   93.1   74.8   79.6   72.9   76.9   71.2   79.4 1511. ]\n",
      " [  92.9   91.5   93.1   94.3   93.7   93.6   88.7   91.5 2144. ]\n",
      " [  48.5   78.5   68.7   68.9   69.4   74.4   59.1   52.3 1358. ]\n",
      " [  51.3   74.6   64.3   60.2   68.3   64.3   54.2   50.4 1147. ]\n",
      " [  45.9   72.8   59.4   74.8   69.2   75.1   61.2   36.5 1292. ]\n",
      " [  67.8   83.2   75.5   81.    73.3   81.    66.2   63.2 1479. ]\n",
      " [  64.3   72.3   68.    65.    71.3   73.2   57.5   54.7 1116. ]\n",
      " [  81.9   78.2   82.5   85.1   84.7   83.    84.3   77.8 1529. ]\n",
      " [  56.    80.5   68.6   69.9   65.3   80.1   79.5   74.6 1257. ]\n",
      " [  54.9   74.3   70.5   68.1   64.7   75.8   63.1   71.7 1388. ]\n",
      " [  81.7   61.6   61.8   62.8   64.1   70.3   69.8   66.7 1226. ]\n",
      " [  61.5   79.    74.6   76.7   71.4   74.8   74.1   80.7 1480. ]\n",
      " [  73.4   84.6   80.9   87.4   76.9   89.5   72.1   70.2 1781. ]\n",
      " [  42.4   67.7   55.6   63.2   58.8   64.2   53.4   48.8 1234. ]\n",
      " [  81.4   85.6   78.5   87.7   78.7   86.6   75.3   66.  1647. ]\n",
      " [  76.9   83.1   77.5   80.    78.9   82.8   73.5   74.5 1556. ]\n",
      " [  58.2   76.5   69.2   77.6   76.4   80.5   68.9   68.7 1390. ]\n",
      " [  55.    67.2   56.7   55.    63.5   55.6   59.2   59.3 1135. ]\n",
      " [  39.4   68.1   51.8   62.2   61.8   64.9   54.2   40.9 1176. ]\n",
      " [  60.    71.8   61.8   64.8   64.    64.1   58.4   59.  1090. ]\n",
      " [  40.4   69.5   56.4   69.9   65.1   68.8   71.4   53.9 1194. ]\n",
      " [  62.3   64.6   53.4   56.4   63.    62.4   54.5   60.4 1252. ]\n",
      " [  58.8   67.4   50.5   59.1   63.    62.1   56.1   60.6 1188. ]\n",
      " [  53.9   58.7   60.9   54.4   58.    57.4   57.6   52.3 1182. ]\n",
      " [  37.8   67.2   48.3   56.6   66.9   59.5   57.8   62.9 1121. ]\n",
      " [  45.7   65.9   54.5   54.9   63.6   63.8   59.7   68.8 1268. ]\n",
      " [  52.2   72.1   55.3   72.5   69.5   71.7   54.2   69.1 1223. ]\n",
      " [  51.1   68.3   63.1   68.    65.6   73.8   57.    56.5 1214. ]\n",
      " [  43.8   65.5   59.1   54.7   64.4   61.2   60.3   65.2 1314. ]\n",
      " [  53.8   79.4   62.8   68.6   69.5   75.7   52.8   45.  1276. ]\n",
      " [  87.5   92.6   91.8   95.4   93.9   93.4   88.1   88.3 2041. ]\n",
      " [  60.8   73.    68.1   78.7   74.5   71.7   63.6   52.7 1291. ]\n",
      " [  85.4   93.4   86.9   93.2   85.5   94.8   85.4   90.  2013. ]\n",
      " [  47.1   74.6   54.9   64.5   61.3   65.7   55.7   57.8 1255. ]\n",
      " [  56.4   77.2   66.7   68.7   71.8   71.2   62.9   62.4 1407. ]\n",
      " [  55.6   69.9   63.    67.3   66.7   66.4   67.2   68.8 1248. ]\n",
      " [  47.6   63.6   61.8   62.2   60.6   68.7   48.1   61.5 1240. ]\n",
      " [  54.2   61.5   67.9   71.2   61.6   67.8   62.    49.7 1192. ]\n",
      " [  62.4   66.2   67.2   57.5   69.5   59.3   70.3   65.4 1128. ]\n",
      " [  57.2   76.6   66.3   68.2   72.3   67.3   53.1   45.9 1327. ]\n",
      " [  40.2   65.3   61.2   64.7   60.5   68.3   57.1   68.  1182. ]\n",
      " [  82.6   88.5   87.4   91.9   89.8   91.    78.4   80.7 1896. ]\n",
      " [  47.    67.6   55.6   58.1   61.    58.8   60.5   57.2 1216. ]\n",
      " [  58.5   69.8   61.3   75.6   62.7   74.7   69.2   62.2 1435. ]\n",
      " [  55.8   67.5   61.4   61.9   64.4   69.2   62.3   61.4 1334. ]\n",
      " [  33.6   71.7   59.7   64.4   63.9   70.6   54.6   35.9 1188. ]\n",
      " [  62.7   69.2   71.7   70.3   71.7   67.6   70.8   66.9 1313. ]\n",
      " [  67.    90.    74.6   83.2   74.7   83.9   71.1   66.8 1643. ]\n",
      " [  56.1   71.4   64.5   64.8   62.5   70.5   66.1   57.5 1179. ]\n",
      " [  57.5   84.8   69.4   77.7   67.4   76.8   71.    77.  1386. ]\n",
      " [  51.9   69.4   68.    68.9   64.1   69.    54.8   61.1 1099. ]\n",
      " [  69.7   66.5   74.1   69.8   68.9   74.6   73.3   83.  1327. ]\n",
      " [  57.1   73.2   58.5   67.7   68.    75.3   61.4   65.  1360. ]\n",
      " [  67.2   76.2   71.6   70.9   69.5   71.7   72.8   81.1 1420. ]\n",
      " [  73.5   71.    72.2   68.5   73.    77.    69.    73.2 1322. ]\n",
      " [  58.1   67.7   67.3   66.8   63.8   72.9   63.5   80.4 1287. ]\n",
      " [  72.7   50.4   63.2   62.8   62.2   62.2   59.2   57.3 1285. ]\n",
      " [  56.4   78.1   69.8   69.6   62.6   74.1   66.1   71.9 1451. ]\n",
      " [  52.7   62.3   63.7   69.3   68.2   70.1   60.4   58.2 1326. ]\n",
      " [  68.9   79.2   75.6   74.6   70.8   76.1   77.1   76.  1580. ]\n",
      " [  67.3   71.8   69.3   76.8   67.3   69.7   66.1   75.8 1386. ]\n",
      " [  74.    85.1   82.    81.1   64.7   82.8   73.9   76.8 1640. ]\n",
      " [  68.7   79.5   73.6   79.4   72.6   77.    75.9   84.9 1404. ]\n",
      " [  59.7   78.5   58.3   63.5   65.9   68.2   69.    76.3 1313. ]\n",
      " [  71.1   77.6   63.5   73.7   77.4   80.5   70.4   74.1 1277. ]\n",
      " [  49.5   65.7   65.4   64.9   64.5   63.3   65.5   76.6 1224. ]\n",
      " [  56.4   67.4   67.5   60.5   62.8   64.1   59.9   77.  1290. ]\n",
      " [  50.    66.9   60.5   72.7   72.7   72.3   63.6   66.8 1211. ]\n",
      " [  59.9   81.    71.2   81.5   66.    82.4   67.6   66.1 1427. ]\n",
      " [  47.6   70.4   59.7   76.2   70.9   66.1   54.1   54.4 1335. ]\n",
      " [  67.9   79.    77.6   77.8   75.    81.6   71.4   81.7 1431. ]\n",
      " [  55.4   74.1   66.1   64.    66.    69.9   68.6   75.5 1314. ]\n",
      " [  72.3   64.8   70.    57.    64.    64.    60.2   64.7 1256. ]\n",
      " [  90.7   91.9   93.7   95.2   87.2   92.7   87.9   87.1 1981. ]\n",
      " [  67.    60.    78.8   74.4   65.3   75.3   72.1   72.3 1578. ]\n",
      " [  77.8   76.8   82.5   76.8   72.9   80.8   77.6   79.5 1530. ]\n",
      " [  50.    68.2   58.5   58.9   63.7   65.1   71.9   71.2 1184. ]\n",
      " [  62.8   70.6   74.3   70.2   70.6   75.6   64.5   64.2 1487. ]\n",
      " [  61.7   74.6   64.5   69.3   62.4   72.9   67.6   64.2 1326. ]\n",
      " [  56.5   74.4   67.    69.4   70.8   71.3   64.8   68.1 1285. ]\n",
      " [  44.5   69.9   66.3   65.2   64.1   65.4   68.8   65.6 1218. ]\n",
      " [  59.7   67.7   64.2   63.5   66.4   62.2   66.7   61.4 1214. ]\n",
      " [  63.    79.6   72.5   77.2   76.1   79.1   68.6   63.8 1397. ]\n",
      " [  69.1   80.3   75.5   79.1   75.1   78.9   71.4   78.2 1193. ]\n",
      " [  63.5   77.    67.9   68.8   69.8   70.4   69.4   64.4 1410. ]\n",
      " [  73.4   79.3   76.2   75.8   69.1   77.2   70.3   71.6 1485. ]\n",
      " [  58.8   70.3   62.9   67.5   66.4   66.8   60.8   56.7 1306. ]\n",
      " [  77.7   79.4   75.6   73.4   70.    80.6   70.7   75.3 1457. ]\n",
      " [  48.    63.8   56.8   60.1   57.9   62.2   55.    58.7 1248. ]\n",
      " [  43.7   69.5   49.8   58.4   62.7   64.3   55.1   47.2 1253. ]\n",
      " [  52.3   81.9   69.7   77.    71.3   79.1   58.4   41.4 1346. ]\n",
      " [  62.4   66.6   65.2   63.5   69.7   70.    69.4   67.1 1316. ]\n",
      " [  41.2   67.4   54.6   61.9   65.7   63.9   51.9   55.6 1265. ]\n",
      " [  64.5   87.4   75.2   81.6   61.7   84.2   67.3   74.3 1622. ]\n",
      " [  75.1   71.8   77.2   67.2   64.5   75.1   76.3   72.1 1274. ]\n",
      " [  67.    65.6   75.    63.4   72.6   77.1   69.3   79.8 1245. ]\n",
      " [  53.8   85.1   74.    79.5   72.5   81.5   77.2   71.9 1409. ]\n",
      " [  58.1   74.4   66.3   66.9   67.2   72.7   66.7   70.  1344. ]\n",
      " [  57.9   67.9   60.3   59.7   65.4   67.    62.8   67.6 1284. ]\n",
      " [  54.5   71.1   62.    63.1   66.5   67.6   64.4   64.  1355. ]\n",
      " [  61.5   78.7   66.7   71.6   66.6   73.4   63.7   66.2 1446. ]\n",
      " [  62.3   77.7   66.5   71.8   65.4   73.3   68.9   71.7 1473. ]\n",
      " [  52.8   69.8   66.7   60.7   63.5   64.5   61.7   61.1 1141. ]]\n",
      "(109, 9)\n"
     ]
    }
   ],
   "source": [
    "#  Also, save the values in df2 after dropping empty rows from df1\n",
    "# DEFINE Columns here -->\n",
    "# extract all the columns that we need\n",
    "df1=np.stack((df['Algebra2/Trigonometry'], df['English'], df['Geometry'],df['Global History and Geography'], df['Integrated Algebra'], df['Living Environment'], df['Physical Settings/Chemistry'], df['Physical Settings/Physics'], df['Average SAT Score (Total)'])).T\n",
    "\n",
    "#remove any empty rows\n",
    "df2=(df1[~np.isnan(df1).any(axis=1)])\n",
    "print(df2)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector and fill with the output values (SAT Score). Create a matrix and fill with the features extracted from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 8)\n",
      "(109, 1)\n"
     ]
    }
   ],
   "source": [
    "# df3 will be our feature matrix\n",
    "df3 = df2[:,:8]\n",
    "#print(df3)\n",
    "\n",
    "# df4 will be the target vector\n",
    "df4 = df2[:,8:]\n",
    "#print(df4)\n",
    "X2 = np.array(df3)\n",
    "Y2= np.array(df4)\n",
    "\n",
    "X = np.array(df3)\n",
    "Y = np.array(df4)\n",
    "\n",
    "# Check the shape of x and y vectors.\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some reshaping here to convert the rank of the y vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 1)\n"
     ]
    }
   ],
   "source": [
    "Y=Y.reshape(Y.shape[0],1) \n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the value of n i.e. number of training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "n=X.shape[0]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending a Column of ones in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.ones((Y.shape[0],1))\n",
    "X=np.hstack((a , X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 9)\n"
     ]
    }
   ],
   "source": [
    "# Shape of x should be [number of training examples (n)] x [number of features + 1]\n",
    "# the 1 comes from the column of ones we just added\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, n):\n",
    "    #Cost can be calculated using a single line of code.\n",
    "    # Remember w is a vector here.\n",
    "    cost=(1/(2*n)) * np.dot(np.ones(n).T, (np.dot(x,w)-y)**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x , y , learning_rate , w , n , num_iters):\n",
    "    # write the updated value of w in temp \n",
    "    for i in range(num_iters):\n",
    "        # derivative vector is given by : X_train.Transpose *  (( X_train * w_vector)- y ) \n",
    "        temp =  w - (learning_rate/n)*np.dot(x.T,(np.dot(x,w)-y))\n",
    "        w = temp\n",
    "        cost= compute_cost(x , y , w , n)      \n",
    "            \n",
    "    return w  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating the Batch Gradient Descent Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating the above function into a single function multiple_linear_reg_model_gda: This function uses gradient descent algorithm to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_linear_reg_model_gda(x , y , n , learning_rate , num_iters):\n",
    "    #initialize the values of parameter vector w. It should be a column vector of zeros of dimension(n,1)\n",
    "    w = np.zeros((x.shape[1],1))\n",
    "\n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost= compute_cost(x, y , w, n)\n",
    "    \n",
    "    #calculate the optimized value of gradients by calling the gradient_descent function coded above\n",
    "    w = gradient_descent(x , y , learning_rate , w , n , num_iters)\n",
    "    \n",
    "    #Calculate the cost with the optimized value of w by calling the cost function.\n",
    "    \n",
    "    final_cost = compute_cost(x, y , w, n)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function to find the optimized values of parameters w. First, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of w. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.77187846]\n",
      " [ 1.67041848]\n",
      " [ 2.22635535]\n",
      " [ 7.77416561]\n",
      " [ 0.79173384]\n",
      " [ 2.30669379]\n",
      " [-0.74975861]\n",
      " [ 1.4527537 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 0.0000029291\n",
    "num_iters = 100000000\n",
    "\n",
    "n = Y.shape[0]\n",
    "w = multiple_linear_reg_model_gda(X , Y , n , learning_rate , num_iters)\n",
    "print(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Equation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to cross-check the optimal values of w we just found using gradient descent above. These values should be same (or nearly same). First calculate q=inverse of (dot of (X.T,X)). Then w= dot of ( X.T , y) and then beta_vec= dot of (q,w). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.01291137]\n",
      " [ 1.81567226]\n",
      " [ 2.41995147]\n",
      " [ 8.45018001]\n",
      " [ 0.86058026]\n",
      " [ 2.50727586]\n",
      " [-0.81495501]\n",
      " [ 1.5790801 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q = np.linalg.inv(np.dot(X2.T,X2))\n",
    "w = np.dot(X2.T,Y2)\n",
    "w_vec = np.dot(q,w)\n",
    "print(w_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Values of w should be approximately same as the ones from multiple_linear_reg_model_gda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a predict function to plot results of learning algorithm and compare them with the plotted actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(x,w):\n",
    "    yhat = np.dot(x,w)\n",
    "    return yhat\n",
    "\n",
    "yhat = predict(X2,w)\n",
    "yhatNormalMethod = predict(X2,w_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEICAYAAABI7RO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXucFNWV+L9nBnGY0aj4iI8BmSgdY0yAcVSITjSaRHxE47L4iA/0Q2Lc1WDySWLQbH7kAVmNrhuJG11WCLoajEpUklXAZ2wTX8ME45MBFcMgCooSEBBmOL8/qhqKprunq7uqq6r7fD+f/nTXrdu3zq176557z7l1r6gqhmEYhlEsdVELYBiGYSQLUxyGYRiGL0xxGIZhGL4wxWEYhmH4whSHYRiG4QtTHIZhGIYvTHEYoSEiQ0RERaSfe/ygiIyrwHV/LCK3h30dI96IyIUi8mTUclQjpjhqHBFZKiIbRGSdiLwjIjNFZJcwrqWqJ6nqrUXK9MUwZHDTv0pE3nDz3C0iv8sRZ6aI9IjIfp6wm93/rBORTSKy2XP8YKnXqkbE4XURednHf44Tke4w5TKCwRSHAfAVVd0FaAXagH/LjuA2BImvL+6I53zgi26e24BHsuI0AWOANcB5mXBVvURVd3H/93Pgd5ljVT2plGsFkJ9+QaYXIJ8H9gE+ISJHRC2MESyJbwiM4FDV5cCDwGEAIvK4iEwRkT8D63Eagd1EZLqIrBCR5SIyWUTq3fj1InKdiLwrIq8Dp3jTd9P7uuf4GyLyioisFZGXRaRVRP4XGAz8we2lX+HGHSkifxGRD0TkeRE5zpNOi4j8yU3nIWCvAtk8Apinqq+5eX5bVadlxRkDfAD8FCjHtFbwWiIyUER+IyJvicj7InJf1r1ZIiKrRWSOiOzvOacicqmILAYWu2GHiMhDbvxFInKmJ/7J7v1d65bZ97IFFZGd3Xt7mCdsb3c0uo+I7CUif3TjrBaRdB8diXHA/cADZN3DXPl2lfWDwP6eUdz+7shvsue/241KRGSiiLzmqUNnFCoQIyBU1T41/AGW4vSIAQYBLwE/c48fB/4OfBroB+wE3Av8N9CE06N8FvimG/8S4FU3nYHAY4AC/Tzpfd39PRZYjtO4CnAwcGC2TO7xAcB7wMk4nZ0vucd7u+efAq4Hdsbp6a4Fbs+T3/OA1cD3cUYA9TniPAL8Avg40AMcniPOj/Ndo9hrAf8H/A7Yw723x7rhxwPv4owAdwZ+BTzh+Z8CD7n3eIBbFsuAi9xyGuH+/1A3/gqg3f29B9CaR94ZwBTP8aXAXPf3vwM3u3LuBLQDkiedRuAfbnmNcWXpX0S+jwO6s9KaCUz2HG8Xx61H+7v14izgQ2A/99yFwJNRP2PV+IlcAPtEXAGcRnodTg/7TeDXwAD33OPATz1xPw58lDnvhp0DPOb+fhS4xHPuy+RXHPOAywvI5FUcPwD+NyvOPJye7GCcxr3Jc+63FGjUgXOBh91G5j3gB55zg4EtwHDPdW7IkcaPC12jr2sB+7nX2SPHf6YDv/Ac7wJsBoa4xwoc7zl/FpDOSuO/gUnu778D3wQ+1oesXwRe8xz/GbjA/f1TnBHEwUXk+TxgFY4Sa8Ax+Z1RRL6Pw6fiyJHGQuB09/eFmOII5WOmKgPgq6q6u6oeqKr/qqobPOeWeX4fiNNDXOGaLD7AaaD2cc/vnxX/zQLXHAS8VqR8BwJjM9d0r3sMTiO0P/C+qn5Y5HVR1TtU9YvA7jijpJ+JyInu6fOBV1R1oXt8B/A1EdmpSFmLvdYgYLWqvp/jb/t786Cq63CUzgGeONnlclTW/TkX2Nc9Pwan9/+ma9IblUfcx4BGETlKRIYAw3FGmADXAkuA+a7Te2KBbI8D7lLVHlXdCMxmm7mqUL59IyIXiMhCT74Po7Cp0giAuDrWjPjgXT55Gc6IYy9V7ckRdwVOw5BhcIF0lwEHFXHNTNz/VdVvZEcUkQOBPUSkyaM8BudIY8eLqG4G7haRH+A0OPOAC4DBIvK2G60fsCdOw3t/X2n6uNZvgYEisruqfpAV/S0cZZDJY5Mrw3Jvkp7fy4A/qeqX8lz7OeB0V/ldBtzF9uWUidcrInfhjCLfAf6oqmvdc2uB7wLfdf0gj4rIc6qaPbGgGcfUdqSIjHGDG4EGEdnLlTVfvnOV2Yfu/zNklGGm7P8HOAF4ypV/IY7p0wgRG3EYRaOqK4D5wH+IyMdEpE5EDhKRY90odwETRKRZRPYACvVKbwG+JyKHi8PBbkMATqP1CU/c24GviMiJ4jjgG1wnabOqvgl0AD8Rkf4icgzwlXwXFWdu/ykisqsr/0k4Ppxn3J74QcCROL3t4Wxr5C/wdbP6uJZ7Lx8Efi0ie4jITiLyefevs4CLRGS4iOyMM4PrGVVdmudSfwRSInK+m85OInKEiHzKvSfnishurvL6B46pKB+/xTF9nev+zuTlVLeMBMf01JsnnfOBLuCTbLuHKaAbOKePfL8D7Ckiu3nSWwic7DrU9wW+7TnXhKNsVrkyXoQ7scMImahtZfaJ9kOWPyHr3OO4PglP2G7ATTgNwRrgr8DZ7rl+wH/imFXewHGu5vRxuMeXAItwfCwvAiPc8NNx7PIfAN9zw44C/oTjbF6F42Ad7J77BJB203kIuJH8zvF/wrHdv4/TiL4AXOieuxmYneM/R+KMtAZ6wn6c7xrFXMs9PxC4FafBfB/4fda9ec3N7x+BZs85JcvXgNNQ/597b97D8TcNB/oDcz0yPAcc04fcS9zreh3a33Hryodu2f8oz39fBb6VI/wKoKOIfM9w5f8Ax2TXgONI/wfwN1cOr3N8iivruzgTJP7ENj/ahZiPI5SPuDfYMAzDMIrCTFWGYRiGL0xxGIZhGL4wxWEYhmH4whSHYRiG4YuqfI9jr7320iFDhkQthmEYRqJYsGDBu6q6d1/xqlJxDBkyhI6OjqjFMAzDSBQiUnDVhQxmqjIMwzB8YYrDMAzD8IUpDsMwDMMXVenjyMXmzZvp7u5m48aNUYuSeBoaGmhubmannUpaMNYwjIRTM4qju7ubXXfdlSFDhuCs02aUgqry3nvv0d3dTUtLS9TiGIYRATVjqtq4cSN77rmnKY0yERH23HNPG7kZRg1TM4oDiE5pbNwIq1Y531WAKV/DqG1qxlQVGRs3wssvbzs+9FBoaIhOHsMwjDKpqRFHJKxd63xv2bL1+L777kNEePXVVwv+debMmbz11lslX/rxxx/n1FNPLfn/hmEYuTDFETa77up819VtPZ41axbHHHMMs2bNKvjXchWHYRhGGJjiCJuGBsc8NWgQHHoo63p6ePLJJ5k+fTp33nnn1mjXXHMNn/nMZxg2bBgTJ07knnvuoaOjg3PPPZfhw4ezYcMGhgwZwrvvvgtAR0cHxx13HADPPvsso0aNYsSIEXzuc59j0aJFUeTUMIwawXwchejqgnQa2tshlSo9nYaGrX6N+++4g9GjR5NKpdhzzz1ZsGABK1eu5P777+eZZ56hsbGR1atXM3DgQG688Uauu+462traCiZ/yCGHkE6n6devHw8//DBXXXUVs2fPLl1ewzCMApjiyEdXF7S2giqIQGdnecrDZdasWVx++eUAnH322cyaNQtV5aKLLqKxsRGAgQMH+kpzzZo1jBs3jsWLFyMibN68uWw5DcMw8mGKIx/ptKM01q+HxkbnuEzFsXr1ah599FFeeOEFRITe3l5EhLFjxxb1/379+rHFdbJ736P40Y9+xBe+8AXuvfdeli5dutWEZRiGEQbm48hHe7sz0mhsdL7b28tO8p577uH888/nzTffZOnSpSxbtoyWlhZ22203fvOb37B+/XrAUTAAu+66K2szs7JwlotfsGABwHamqDVr1nDAAQcAjkPdMAwjTExx5COVcsxTU6cGaqY644wztgsbM2YMK1as4LTTTqOtrY3hw4dz3XXXAXDhhRdyySWXbHWOT5o0icsvv5y2tjbq6+u3pnHFFVdw5ZVXMmLECHp6esqW0zAMoxCiqlHLEDhtbW2avZHTK6+8wqc+9amIJKo+7H4aRvUhIgtUtfBsHGzEYRiGYfjEFIdhGIbhC1MchmEYhi9McRiGYRi+MMVhGIZh+MIUh2EYhuELUxwVpL6+nuHDh3PYYYcxduzYrS/8lYJ3yfQ5c+Zw9dVX5437wQcf8Otf/9r3NX784x9vfafEMAwjgymOCjJgwAAWLlzIiy++SP/+/bn55pu3O6+qW5cU8cNpp53GxIkT854vVXEYhmHkwhRHRLS3t7NkyRKWLl3KJz/5SS644AIOO+wwli1bxvz58xk1ahStra2MHTuWdevWATB37lwOOeQQWltb+f3vf781rZkzZ3LZZZcB8M4773DGGWcwbNgwhg0bxl/+8hcmTpzIa6+9xvDhw/n+978PwLXXXssRRxzBZz/7WSZNmrQ1rSlTppBKpTjmmGPitTx7VxdMn+58G4YRKbbIYQGCWlU9m56eHh588EFGjx4NwOLFi7n11lsZOXIk7777LpMnT+bhhx+mqamJa665huuvv54rrriCb3zjGzz66KMcfPDBnHXWWTnTnjBhAsceeyz33nsvvb29rFu3jquvvpoXX3yRhQsXAjB//nwWL17Ms88+i6py2mmn8cQTT9DU1MSdd97JwoUL6enpobW1lcMPPzy4jJdKSCsVG4ZRGqY48hBGW7VhwwaGDx8OOCOO8ePH89Zbb3HggQcycuRIAJ5++mlefvlljj76aAA2bdrEqFGjePXVV2lpaWHo0KEAnHfeeUybNm2Hazz66KPcdtttgONT2W233Xj//fe3izN//nzmz5/PiBEjAFi3bh2LFy9m7dq1nHHGGVuXdz/ttNPKy3BQhLBSsWEYpWOKIw9htFUZH0c2TU1NW3+rKl/60pd22FY21/9KRVW58sor+eY3v7ld+C9/+cvArhEoIaxUbBhG6ZiPIw9RtVUjR47kz3/+M0uWLAHgww8/pKuri0MOOYSlS5fy2muvAeTdr/yEE07gpptuAqC3t5c1a9bssDz7iSeeyIwZM7b6TpYvX87KlSv5/Oc/z3333ceGDRtYu3Ytf/jDH8LMavGEsFKxYRilYyOOPGTaqjB8HIXYe++9mTlzJueccw4fffQRAJMnTyaVSjFt2jROOeUUGhsbaW9v304ZZLjhhhu4+OKLmT59OvX19dx0002MGjWKo48+msMOO4yTTjqJa6+9lldeeYVRo0YBsMsuu3D77bfT2trKWWedxbBhw9hnn3044ogjKpPpYkilTGEYRkywZdWNkojF/Qxr9oJh1CiRL6suIoNE5DEReVlEXhKRy93wgSLykIgsdr/3cMNFRKaKyBIR+ZuItHrSGufGXywi48KS2UgQmdkLEyY43zZN1zAqRpg+jh7gu6p6KDASuFREDgUmAo+o6lDgEfcY4CRgqPu5GLgJHEUDTAKOAo4EJmWUjVHDeGcvqDrHhmFUhNAUh6quUNVO9/da4BXgAOB04FY32q3AV93fpwO3qcPTwO4ish9wIvCQqq5W1feBh4DRJcpUcn6MbcTiPtpMK8OIjIrMqhKRIcAI4Bng46q6wj31NvBx9/cBwDLP37rdsHzh2de4WEQ6RKRj1apVO8jQ0NDAe++9F49GL8GoKu+99x4NDQ3RCmIzrQwjMkKfVSUiuwCzgW+r6j9EZOs5VVURCaQlV9VpwDRwnOPZ55ubm+nu7iaXUjH80dDQQHNzc9Ri2Ewrw4iIUBWHiOyEozTuUNXM4krviMh+qrrCNUWtdMOXA4M8f292w5YDx2WFP+5Xlp122omWlha/fzMMoxLYDLlEEeasKgGmA6+o6vWeU3OAzMyoccD9nvAL3NlVI4E1rklrHvBlEdnDdYp/2Q0zDKMasBlyiSPMEcfRwPnACyKSWS/jKuBq4C4RGQ+8CZzpnnsAOBlYAqwHLgJQ1dUi8jPgOTfeT1V1dYhyG4ZRSWwtssQRmuJQ1ScByXP6hBzxFbg0T1ozgBnBSWcYRmywGXKJw5YcMQwjWqJa38coGVMchmFEj82QSxS2Oq5hGIbhC1MchmEYhi9McRiGYRi+MMVhGIZh+MIUh2EYhuELUxyGYRiGL0xxGIZhGL4wxWEYhmH4whSHYRiG4QtTHIZRiK4umD7dVmw1DA+25Ihh5COz3Leqs/ie7TRoGICNOErDeqG1gXe5b1Xn2DAMG3H4xnqhtYMt920YObERh1+sF1o7ZJb7njrVOgiG4cFGHH6xXmhtYct9G8YOmOLwi206YxhGjWOKoxSsF2oYRg1jPo4KYJOwDMOoJmzEETI2CcswjGrDRhwhY5OwgsFGbdWNlW+ysBFHyNgkrPKxUVt1Y+WbPGzEETL2KkD52KiturHyTR424qgANgmrPGzUVt1Y+SYPUxxG7LFXZ6obK9/kYYrDSAQ2aqturHyThfk4DMMwDF+EpjhEZIaIrBSRFz1hw0XkaRFZKCIdInKkGy4iMlVElojI30Sk1fOfcSKy2P2MC0teI3nYFE7DiIYwTVUzgRuB2zxhvwB+oqoPisjJ7vFxwEnAUPdzFHATcJSIDAQmAW2AAgtEZI6qvh+i3EYCsCmchhEdoY04VPUJYHV2MPAx9/duwFvu79OB29ThaWB3EdkPOBF4SFVXu8riIWB0WDIbycGmcBpGdFTaOf5tYJ6IXIejtD7nhh8ALPPE63bD8oXvgIhcDFwMMHjw4GClNmKHTeE0jOiotHP8X4DvqOog4DvA9KASVtVpqtqmqm177713UMkaMcVerDSM6Kj0iGMccLn7+27gFvf3cmCQJ16zG7YcxwfiDX88VAmria6uqp4cb1M4DSMaKj3ieAs41v19PLDY/T0HuMCdXTUSWKOqK4B5wJdFZA8R2QP4shtm9EXGezxhgvNtU48MwwiI0EYcIjILZ7Swl4h048yO+gZwg4j0Azbi+iSAB4CTgSXAeuAiAFVdLSI/A55z4/1UVbMd7kYuvN7jxkbn2LrnhmEEQGiKQ1XPyXPq8BxxFbg0TzozgBkBilYbmPc4EKrc2mcYJWFLjlQrtgBQ2di7IoaRG1Mc1Yx5j8vCrH2GkRtbq8ow8mDWPsPIjY04DCMPZu0zjNyY4igBc5jWDmbtM4wdMcXhE3OYGoZR6/Tp4xCRRhH5kYj8j3s8VERODV+0eGKL6xmGUesU4xz/DfARMMo9Xg5MDk2imGMOU8Mwap1iTFUHqepZInIOgKquFxEJWa7YYg5TwzBqnWIUxyYRGYCzlwYichDOCKRmMYepYRi1TDGmqknAXGCQiNwBPAJcEapUScL2LzUMo8YoOOJwTVKvAv8EjAQEuFxV362AbPEjex6uTbEyDKMGKag4VFVF5AFV/QzwfxWSKZ7kUhK2JoVhGDVIMaaqThE5InRJ4k6uebg2xcowjBqkGOf4UcC5IvIm8CGOuUpV9bOhShY3cikJm2JlGEYNUoziODF0KZJAPiVhU6wMw6gx+lQcqvqmiAwDMnaYtKo+H65YMcWUhGEYRlFLjlwO3AHs435uF5FvhS1YUrDZuIZh1BrFmKrGA0ep6ocAInIN8BTwqzAFSwJJnY1rq/sahlEOxSgOAXo9x71uWM2TxNm4SVV2hmHEh2IUx2+AZ0TkXvf4q8D08ERKDnGfjZtrZJFEZWcYRrwoxjl+vYg8DhzjBl2kqn8NVaqEEOfZuPlGFu3tILqFxv69iNbT3m67BxuG4Y8+FYeIjAReUtVO9/hjInKUqj4TunQJoBITrUrxSeQbWaToopMzSTOKdp4ixV1AjDReNRJnp1KcZTNiSzGmqpuAVs/xuhxhRkiU6pPIa0ZLp0nJYlKbnjdbVSWIs1MpzrIZsaYYO4WoqmYOVHULtuVsxSh1x8GMGW3q1Kz2IO6OmWojzltGxlk2I9YUowBeF5EJOKMMgH8FXg9PJMNLOe18TjNanB0z1UicFXWcZas2qswkKJ7BRO4IIvsAU4Hj3aCHgW+r6sqQZSuZtrY27ejoiFqMwKiyOld7xLkA4yxbtZAgk6CILFDVtr7iFTOraiVwdiBSGSVhK50knDgXYJxlqxaqcA58Xh+HiHxDRIa6v0VEZojIGhH5m4j06Rh3468UkRezwr8lIq+KyEsi8gtP+JUiskREFonIiZ7w0W7YEhGZWFo2DcMwIqIKTYKFRhyXAzPd3+cAw4BPACOAG9i26GE+ZgI3ArdlAkTkC8DpwDBV/cg1gyEih+KMaj4N7A88LCIZlfxfwJeAbuA5EZmjqi8XmT/DMIxoqUK/YqFZVT2qutn9fSpwm6q+p6oPA019JayqTwCrs4L/BbhaVT9y42T8JKcDd6rqR6r6BrAEONL9LFHV11V1E3CnGzcS/CxoaIsfGoaxlVQKxo+vCqUBhUccW0RkP+B94ARgiufcgBKvlwLaRWQKsBH4nqo+BxwAPO2J1+2GASzLCj+qxGuXhR//VoJ8YYZhGL4pNOL4f0AHsBSYo6ovAYjIsZQ+HbcfMBAYCXwfuEtEAlkwUUQuFpEOEelYtWpVEEluh58p7zY93kgKNjI2SiHviENV/ygiBwK7qur7nlMdwFklXq8b+L37QuGzIrIF2AtYDgzyxGt2wygQni3vNGAaONNxS5QvL378W0nyhdlszBoiq7BtZGyUSsHpuKrag2Oq8oZ9WMb17gO+ADzmOr/7A+8Cc4Dfisj1OM7xocCzOMu3DxWRFhyFcTbwtTKuXzJ+/FtJ8YVZw1FD5CjsdDoVv1mi1pNJBKEtHSIis4DjgL1EpBuYBMwAZrhTdDcB49zRx0sichfwMtADXKqqvW46lwHzgHpgRsZkFgV+prwnYXp8FU4vjyWxaAtzFHZ7eypeI2PrySSGvIpDRAar6t9LTVhVz8lz6rw88aewvQM+E/4A8ECpchj5SZJJLanEpi3MUdixGxlbTyYxFBpx3IetgFvVxK7hqEJi0xbmKexYjYytJ5MYCikO2x62BkjRRYo0zvuccWlBqodYtYWx0hI5sJ5MYiikOA4Qkan5TqrqhBDkMSpJbOwo1Yu1hT7xKLdY+IYCopryAoUVxwZgQaUEMSIgNnaU6ibuHf04Uk19mmrKS4ZCiuM9Vb21YpIYlSdWdhTD2EY19WmqKS8ZCr05vqliUhhbqeibvHm3CTSM4CilTofdp6nkc1aN/bNCb46PzA4TkYNwXsA7W1U/HaZgtUjeIW2YBlKzoxguYVSzUs00qRR0zn6D9Kxu2s9pJpVqCUagMmQqlWr0c/X5AqCI7I+zxMjXgM8A/45t7BQKOYe0VKGB1IgdYTWmJZtpurpIjWklpQr3BFvvozAdVVv/rNBGTheLyGPA48CewHhghar+RFVfqJB8NUXOIa2tmGhUgLCqWclmmhDrfTWajipNoRHHjcBTwNdUtQNARAJfPLBqKWHcn3tIa7XcCJ+wGtOSzTQhtu7VaDqqNOIsFZXjhMiewFic3f/2Be4CLlTVQTn/ECPa2tq0o6MjOgGCHvdX2yRwI5bErprFRKCYiFERRGSBqrb1Fa+Qc/w94GbgZhFpxvFzvCMirwD3qupVgUlbbQRtRK02A6kRS4KoZoE2shWu97lkr8Z3MIKgqNVxVbUb+A/gP0RkKM4oxMiHGVGNGiTJjWw+2avxHYwgKOQcP0JE9vUcXyAi9wPfwvF/GPmw9yOMGiTJ8zjyyW59wNwUegHwv3FfAhSRzwNXA7cBa3B32jMKUGWb0xtGX1SskQ3h7b32dhDdQmP/zYhu2Sp7pfqASdvCt5Cpql5VV7u/zwKmqepsYLaILAxftBolCCNxLXnzjNhQkdlKIdnDUnTRyZmkGUU7T5HiLjKrRYftakmiia+g4hCRfu72sScAFxf5P6NUgqhBXV10DT+TdO8o2ut/RWrhXfGvhUZFqER/InR/dlhOh3SalCwmten5ijszyspSRJ3EQgpgFvAnEXkXZ6XcNICIHIxjrjKCJoCHouvu52nd8CSKs6FK590PkvqhKY44UslnPom92pyUYQ8reL8jdGaUfOkIC7XQdNwpIvIIsB8wX7e98FGH4yA3giaAypumHUVYTxONfEiadtueKYZU+pmvmtlBJdrD+rzfEb4VWPKlIyzUgiYnVX06R1hC3DcJJIDK2z52X2TKFhp7NyP1A2gf21TU/8wtUlkq/cyX0yeJXd0owR5W1P3Ol24FbkBJJr4IR0nmq4gbZRqJUynoXFhHOl1XdD2vGjNGggj1mc/R0JXaJ6mWupFEc1CfRDhKMsVRhfjVPVVjxkgQoT3zBRq6TL3ITP0s5rrVUjeSaA7KS3bHIAJ5THEY9pJTRITyzPfR0PntQFdT3UiaOSgnMRkBFXoB0KgR7EX3EojrG1t9NHR+3+6u+boRtxsQk9fzbcRhALaOoi9i0uvLSR82mVI60GXXDR/O5dg54iFeD0dMRkCmOAIklpXeCJ442r29FGjoQvenZj8EPpRsnPVxbIjQIe7FFEdAWKWvDLFQzhH0+rrmbdt/m5aWsu5BaB3oXA+BDyUbd30cG2IwAjLFERBW6cMnNso5xF5fzj0h5r1B6+i9UfZBbwUatiB1dfHroOR6CHwo2ZhYYYwiMMUREFbpw6do5ZzQRZny7gkxqxtlH9bTRH8+gs3Kpt4YdlByPQQ+lGwkVphYDGFjJEexqGooH2AGsBJ4Mce57wIK7OUeCzAVWAL8DWj1xB0HLHY/44q59uGHH65RsGiR6i23ON9G8CxapNrUpNrY6HznvM9FRYont9ziiA3O9y23OOGL5r6uTazVRtbpANbpgIbecLIXRAVO0kMQUF3xk+WccWNUZ4EOLaKNDXPEMRNnw6fbvIEiMgj4MvB3T/BJwFD3cxRwE3CUiAwEJgFtOIpmgYjMUdX3Q5S7ZGJgeqxqiuqRJthmmG/Umjqxhc65wfk4chKUHTDOD0F2rz6IRUV93La8cRNYZ0NTHKr6hIgMyXHqP4ErgPs9YacDt7ka72kR2V1E9gOOAx5Sd18QEXkIGI2zcq9Rg/TZLiXYZlhIMaZObCF1Yst2cQMlgY2XL3K12kEsKurjtuWNG9aKvyFSUR+HiJwOLFfV50XEe+oAYJnnuNsNyxeeK+2LcfcMGTx4cIBSx5gmRTqMAAATy0lEQVQga03SbKz5iMl0xaLIs6ZU6CLnKusEKdySqmquVnv8+PIXFfVx2/LG9VlnM/lvboYxY6KZLFIxxSEijcBVOGaqwFHVabhb2ra1tWkf0RPL1oem+Q1SYwKaYhSb6UoBEWdzSYao7nm+6yZE4ZZ82/LaAcurK35uW8G4RcrhzX9PD9TXw4YNlR8kVnLEcRDQAmRGG81Ap4gcCSwHBnniNrthy3HMVd7wxysgayzZ7qHpbaZTDiK18W/l15pqN1PEkajueaHrJkDhlnzbQlSMfm5bubfYm/+GBtiyJZpBYsUUh6q+AOyTORaRpUCbqr4rInOAy0TkThzn+BpVXSEi84Cfi8ge7t++DFxZKZnjxnYPzYB60r1Hk2pcUn6tSZCZIi6UbdmL6p4nvKzLEj8BirEvsvM/ezZ0d1eRj0NEZuGMFvYSkW5gkqpOzxP9AeBknOm464GLAFR1tYj8DHjOjffTjKO8YsTI9r99pamj/d7vQ/fh5cuWEDNFXAjEylThlwgrcd1KkHDxyyYu+RfV6nMHtLW1aUdHR/kJxdD2HyM9VrNMnw4TJmwzl0yd6vhZvQRSTiUkEsMqa+Qhjs+yiCxQ1ba+4tmb44UI2g4dQE3xjrbjWPFqgb7MJYE03iUmYu4qf0T1DPku3pg97KY4ChGkPTjgrqD1LKOjL3NBII13iYkk3IVRMqW0q1E+Q76KN4YPuymOQgRpUAy4K2g9y2gp5GcNpPEuMZG42MArRVcX3H03TJni3CY/7Wpgz1AJWqtg8YbwhnvQmOLogy5SpEnRDpRVVAF3BZPeswxz5B31qD6QxruIRPLlswomDxVFpiO+eTNs2uSE+WlXA3mGShwN5C3ekN5wDxpTHAUIdIQYcFcwyT3LMEfekYzqw3oDvEAiMbRebE8FtHemI55RGv37+2tXA3mGyhgN5CzedJqu3oNIb2yjvaGDVEBvuAeNKY4C+K4TfT0sAXcFk9qzDHPkXVbacTCUFylDnKwXO4jc1UXX8DNJ946ivf5XpBbeFYpw3o64KvzwhzB2rL9Llf0MBTwa6Go+ntaNZ6EIslHpbF7lWDpi9rCb4iiArzoRQhcwapNLWIQ58i457VLLL8gWvFgZurpof/t5RMfQ2FhXOJ8hV6JcInP387RueBLF2S+h8+4HSf0w+GunUtA5e9uqwd5FICtGwEP/dHcLOmAL6zfU0ThgC+nulvJM5CFhiqMAvupEEQ2In2fYbzuWJCUTppmt5LRLVQBBasEsGbrufp70vqmcNvCUKp1MIX3VXNrH7ptb1ArYs3LdNmhHEdbTRCMfkqY9nMavq4vUGOdecE+E9roA58i3t4PU1W17yTd6d0Zuitm0I2mfSDZy6mMzFr97teTb1KeESycLz043Fd0TqJybmEvQUoT3yLBowDBtGpBjwyY/FcNP3GLyVFjkrXIuWqSO7P03adOA3h03LQqqUMvJXxhEsDFU0BCDjZxqiz66un47tH46snGyd5eFp4fcpUNppROVCu2tnUrRNfuFbWaPlA+zR7b92WdPf1snNUXKrUPpt09Bf15X3t4NpY6GfMifr9p3Lqwjna7re8ZQOYUaps2zlJFDQA9izNwZuSlGuyTtE9XWsYUo1BnJ18MotudRNSMOTw/ylv6XaGP/TRXrTAZ6D330hPNdt6A8Ze9VGpz8vggj3TC656VWhip4ELERR7zI1zMr1AkrtueR5Km52+HpQbbrUwj1FZu6HuiozUdPON91C5apny5pKd3XsHry7e106VDS/UfRrk+RCiLdMLrnpVaGqnkQ+8YURwXJVcfTadAtnlkU6bqS6lsihrd5yGWqSbW300ld7hekfDyYuaKHvgGejwak0HUjK9NizHalLMBIyjE/0otQTyd1sZwxVJaCS/KD6ANTHBHT3vwGsmFvGhFkg9LevApnv6vaYMcRV4rUePclOrKewRJ8BztMFaVCG+AV2YCUdV1v4w05Eyn51ZQxLai2IPfkuM3lLMAodazfVBe8Ly7AaYXlKLhAZzfGeKqkKY6ISXU/SmfD1G1vinZPAMb3+b9qwZdVwKcJIfdU0fhtgFfSdb2Nt7pbI2Qt1hTaqylxW4AxYKd7qQouUDFivjRAXdQC1Dzt7aTqX2N8452k6l+LxTo0laTPxd6mT3e++4xcXNoxXPanNLyNd2+v81m/3glzNaQ3iie4T3a4R81vlFUOGTKjq6lTA24HS81oHkqtI0WJkV2ny0osQorxoCftE8dZVQWJcuK2DwIRM0ciOdMtNN3IhxBBvWIRFIFd23t/BgxwPln3KpBXU+a+Hkg5hEoIs5nKfA0ntxh+5IxohhZFzqqKvJEP41O24ojTQxETAqnHfhKJ28tdARB4W+Ctp3nqbNlVOSnlEJNndjsxsmXyey8jyFOxisN8HNnE3LYYlcMskOmqfhKpGpvSNgJ/UTPbOZIjsbL9Np5y6NKhpN8+hfaueD0SQGxmM20VI4jl0WOSp1yYjyObONsWM5VxwgTnuy87aYDkrfPF2mwLJpIDvwZxP3JERCJ1oVsOXVfNpJVOJvx8X1pbYd688m9317w3mH5hmq55bwQnb6Xoq77lakfKcPLErnoXMyxJ2qcsU1Wc3/6M2Gyww8i5lHtV6Td9Y2LCyBCWOGFn01v1GhpUd965vEdk0dzXtYm12sg6bWKt40sJgcDvy6JFqpMn5/Qp7RAvoHakkk0SZqoqkTi//Rlxl3WHkXMptpdKvukbQ7NjGNmvRDa9Va+nB+rryzO5pWd1o+yzbQXdWd2BL4se+H3xs+VgMe1IAvdeyWCKIxdxtS3GTanFxfaSTw7vE9fQAD//OVx1VeD3Ler3tCrRsHirXnMzjBlTXrG3n9OM3Ko08iGC0n5Oc2CyZsrj7bcDvi+ZG13sloOF2hEfWi0uj9l2FDMsSdqn3FlVMbNuBEPAmdpuumYcbla+ebdNTY5tBRzzQsBj/ThYNqOQIYjqtGju63rLuCcCNVMVMUs5uMQnTy49UZ9m50q1Sdh03NKIQ0NQEoVqVsCZStQ9WrRIddw450EPwTcUl9mqVdnZKYHs8pg8OQQfRxAJFvEQRVGmxSoOM1VlEUd7Yp/0NewNOFOBJFcp+04q5Zin7rknlLF+XMwIFbGuRm2TK4Ls8vC7B3mfBHWj+zA7l+KfqWTxmOLIIi4NgS/6askDzlTZyWU/FbNnQ3d3WTW+4ENTzGqvxaSXIzBubqfQiOFEg1ykUln7kLMZpse0cAooIb+ds4oXTzHDkqR9kuDjCPQaxdiOwvJxlJJcwHM7+8q+39m6OeMnyj4XAoVscnGyk4Xq5KgcfqtbUCZTojZVicgM4FRgpaoe5oZdC3wF2AS8Blykqh+4567EWRa2F5igqvPc8NHADUA9cIuqXh2WzBnCHvYH3jsoptsbcKbKSi7guZ199c78ztbNGZ8k2jADJN8wM24jEW/h9e/vhG3alLgy8zuSrbSlJExT1UzgRuA2T9hDwJWq2iMi1wBXAj8QkUOBs4FPA/sDD4tI5lb9F/AloBt4TkTmqOrLIcodOqH4UeI6hTgXAc/t7OuhKWa2rrcccsdPog0zQPK1ZHFzCnoLT93l5hNaZn4e6UqbTENTHKr6hIgMyQqb7zl8Gvhn9/fpwJ2q+hHwhogsAY50zy1R1dcBRORON26iFUci/SjZlOuJ8z4VZdb4vh6afOfzlUPu+LXizChArpYsbpU5u/Agd5klwNHvl0r2HUUzWjmMxB3F8ceMqSrr3B+A36nq7SJyI/C0qt7unpsOPOhGHa2qX3fDzweOUtXLcqR3MXAxwODBgw9/8803Q8hRcCS63uYzTyQlUx45u0jVxI5toZK0fMfNvBYjRGSBqrb1FS+SWVUi8kOgB7gjqDRVdRowDaCtrS08bRgQSbIs7UC+rfUCnikVClmNRqqzc+tWtTvE89MY1nJjVIHK3DXPM1Oq3KVJ4mZeSyAVVxwiciGO0/wE3TbcWQ4M8kRrdsMoEG5ERS7zRDpNV+9Bzha4/Z8ldfrpjtM7bo1oMY1GKUqg2MYoab3zGNA17w1aR++Nsg9yq9I5943ylEfczGsJpKKKw50hdQVwrKqu95yaA/xWRK7HcY4PBZ4FBBgqIi04CuNs4GuVlLnmydXQeezIXc3Hk0630MwAxmw8C0WQTUrnzp8jtf6F+PXoimk0SumRFpNuLY9KyiDwBRFr5uWb8AhzOu4s4DhgLxHpBibhzKLaGXhIRMDxa1yiqi+JyF04Tu8e4FJV7XXTuQyYhzMdd4aqvhSWzEYWhRq6VIouUltP9/QMon7nLWz4qI7GnXtI6zGkGl+LX4+umEajlB5pMemaiaQkQlkQMdG24ugJc1bVOTmCpxeIPwWYkiP8AeCBAEWrSUqykPTR0GUvPrtF69y2th/ts78P3YfHs0fXV6NRYo+0ixRpUrQDOf9hJpKSSJ3YQufcAH0cFaKarZKhzqqKira2Nu3o6IhajNhQsoWkjz+GsHJIYin6Hldza1IDFFt8SbVKxnpWlVFZSraQ9NHzNlPxNoq+x2YiSSx+lEG1WyVNcURFBXueZVlI+mjorB10MCtU9eNHGVR7fTDFEQUVHsfayCB87B5XP36UQST1oYKdUVMcURDBONbXyMDs8CVho6/qxq8yqGh9qHBn1BRHFMR5HNvVRdfwM0n3jqK9/ldw772ku1sC0yGx00k+BIqd7EbFiW3noMKdUVMcURBju0bX3c/TuuFJFFAETtsZ6RdMJyZ2M018CBQ72Q3DS4U7o3Whpm7kJ5WC8eNj1/qkaUcR1rMLvfSjV+tYv95pMDNLUvmmqwumTyd999tbO0X50nOj0tVVVjaKw9tL6yODPqIaRuXJdEanTq1Ir8ZGHHEmAttI+9h9kSlbaOzdjMpOUFdH405ldGI8XfV2/RVCJ42NdTnTq3iv3kcvLc7WRaPyxNJsWUE7mimOuBKRbSSVgs6FdaTTdQW3MygaT1c91biYzqtmk953bM70Kj5nwIfJMMbWRaPCmNnSFEd8ifANouyOSymX3dojaz6elKernho7LF5z33300mLrGDUqSrW/3FcMpjjiSoJtI9v3yFronP0Cqe5HrVefj1jaPYx8JPjRDAxTHHElwa3oDj2y7hZS48cX9d+a69Wb3SNxJPjRDAxTHHEmbq1okT3j7B5Zc7MzU6pWH7KCmN0jkcTt0aw0pjiM4vDRM/b2yJqbYcwY61DnxeweRgKx9ziM4vD5IkPmNZXubnv/oSAVnn9vGEFgIw6jOErsGVuHughq3e5hJA5THEZxlOgRNEeiYVQfpjiM4imxZ2wdasOoLszHYRiGYfjCFIdhGIbhC1MchmEYhi9McRiGYRi+MMVhGIZh+MIUh2EYhuELUxyGYRiGL0RVo5YhcERkFfBmmcnsBbwbgDhxxfKXbKo5f9WcN4h3/g5U1b37ilSViiMIRKRDVduiliMsLH/JpprzV815g+rIn5mqDMMwDF+Y4jAMwzB8YYojP9OiFiBkLH/JpprzV815gyrIn/k4DMMwDF/YiMMwDMPwhSkOwzAMwxemOHIgIqNFZJGILBGRiVHLUw4iMkhEHhORl0XkJRG53A0fKCIPichi93uPqGUtBxGpF5G/isgf3eMWEXnGLcPfiUj/qGUsFRHZXUTuEZFXReQVERlVTeUnIt9x6+aLIjJLRBqSXH4iMkNEVorIi56wnOUlDlPdfP5NRFqjk7x4THFkISL1wH8BJwGHAueIyKHRSlUWPcB3VfVQYCRwqZuficAjqjoUeMQ9TjKXA694jq8B/lNVDwbeB8ZHIlUw3ADMVdVDgGE4+ayK8hORA4AJQJuqHgbUA2eT7PKbCYzOCstXXicBQ93PxcBNFZKxLExx7MiRwBJVfV1VNwF3AqdHLFPJqOoKVe10f6/FaXQOwMnTrW60W4GvRiNh+YhIM3AKcIt7LMDxwD1ulMTmT0R2Az4PTAdQ1U2q+gFVVH44O5EOEJF+QCOwggSXn6o+AazOCs5XXqcDt6nD08DuIrJfZSQtHVMcO3IAsMxz3O2GJR4RGQKMAJ4BPq6qK9xTbwMfj0isIPglcAWwxT3eE/hAVXvc4ySXYQuwCviNa4q7RUSaqJLyU9XlwHXA33EUxhpgAdVTfhnylVci2xtTHDWCiOwCzAa+rar/8J5TZ052Iudli8ipwEpVXRC1LCHRD2gFblLVEcCHZJmlEl5+e+D0uluA/YEmdjTzVBVJLq8Mpjh2ZDkwyHPc7IYlFhHZCUdp3KGqv3eD38kMid3vlVHJVyZHA6eJyFIcs+LxOD6B3V3TByS7DLuBblV9xj2+B0eRVEv5fRF4Q1VXqepm4Pc4ZVot5ZchX3klsr0xxbEjzwFD3Vkd/XEcdXMilqlkXHv/dOAVVb3ec2oOMM79PQ64v9KyBYGqXqmqzao6BKesHlXVc4HHgH92oyU5f28Dy0Tkk27QCcDLVEn54ZioRopIo1tXM/mrivLzkK+85gAXuLOrRgJrPCat2GJvjudARE7GsZvXAzNUdUrEIpWMiBwDpIEX2OYDuArHz3EXMBhnCfozVTXboZcoROQ44HuqeqqIfAJnBDIQ+Ctwnqp+FKV8pSIiw3Ec//2B14GLcDp9VVF+IvIT4CycGYB/Bb6OY+dPZPmJyCzgOJzl098BJgH3kaO8XGV5I455bj1wkap2RCG3H0xxGIZhGL4wU5VhGIbhC1MchmEYhi9McRiGYRi+MMVhGIZh+MIUh2EYhuELUxyGYRiGL0xxGIZhGL74/zqRM6RzW+isAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plot predicted values and y to see simiarities\n",
    "import matplotlib.pyplot as plt\n",
    "X2 = np.arange(0,Y2.shape[0])\n",
    "plt.scatter(X2,Y2,color ='red',s=8, label = \"Actual\")\n",
    "#plt.scatter(y,yhat,color ='blue',s=8)\n",
    "plt.scatter(X2,yhatNormalMethod, color='blue',s=8, label = \"Predicted\")\n",
    "plt.ylabel(\"SAT Score\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"Predicted SAT Scores vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8671015895873929\n",
      "0.6993012720703827\n"
     ]
    }
   ],
   "source": [
    "def calculateR2(y,yhat):\n",
    "    ym = np.mean(y)\n",
    "    rss = np.sum((y-yhat)**2)\n",
    "    ess = np.sum((yhat-ym)**2)\n",
    "    tss = np.sum((y-ym)**2)\n",
    "    return ess/tss #R^2\n",
    "\n",
    "rsq1 = calculateR2(Y2,yhat)\n",
    "rsq2 = calculateR2(Y2,yhatNormalMethod)\n",
    "print(rsq1) \n",
    "print(rsq2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707.2436739828822 1002.8372987561428\n"
     ]
    }
   ],
   "source": [
    "#Min and max values for predicted set\n",
    "yhatmax = np.amax(yhat) \n",
    "yhatmin = np.amin(yhat) \n",
    "print(yhatmax,yhatmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
