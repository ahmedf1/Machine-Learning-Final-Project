{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import some libraries to do some data manipulation, math, and modeling.\n",
    "\n",
    "For polynomial regression, you want to pick the order/degree based on both low training error and low test error. This means it generalizes well represent the test and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy.polynomial.polynomial as poly\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas module to read the file and import into a dataframe. Print the data frame to make sure that the data is being imported correctly. Using \"dataframe.values\" returns a Numpy representation of the DataFrame to be spliced according to however is necessary. Reshape the feature matrix and target vector to both be of the same rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  52.6   71.9   66.4   61.    64.3   64.4   63.    64.7 1265. ]\n",
      " [  64.2   72.5   65.    66.9   63.5   70.8   65.7   71.5 1367. ]\n",
      " [  77.    74.    80.9   81.8   71.6   84.8   67.9   80.2 1700. ]\n",
      " [  81.2   88.2   84.2   90.9   88.2   90.7   83.1   79.9 1889. ]\n",
      " [  81.4   75.7   79.6   88.9   80.5   87.5   76.9   72.4 1704. ]\n",
      " [  64.    78.    72.1   72.6   72.6   73.2   73.1   74.1 1327. ]\n",
      " [  84.3   93.1   74.8   79.6   72.9   76.9   71.2   79.4 1511. ]\n",
      " [  92.9   91.5   93.1   94.3   93.7   93.6   88.7   91.5 2144. ]\n",
      " [  48.5   78.5   68.7   68.9   69.4   74.4   59.1   52.3 1358. ]\n",
      " [  51.3   74.6   64.3   60.2   68.3   64.3   54.2   50.4 1147. ]\n",
      " [  45.9   72.8   59.4   74.8   69.2   75.1   61.2   36.5 1292. ]\n",
      " [  67.8   83.2   75.5   81.    73.3   81.    66.2   63.2 1479. ]\n",
      " [  64.3   72.3   68.    65.    71.3   73.2   57.5   54.7 1116. ]\n",
      " [  81.9   78.2   82.5   85.1   84.7   83.    84.3   77.8 1529. ]\n",
      " [  56.    80.5   68.6   69.9   65.3   80.1   79.5   74.6 1257. ]\n",
      " [  54.9   74.3   70.5   68.1   64.7   75.8   63.1   71.7 1388. ]\n",
      " [  81.7   61.6   61.8   62.8   64.1   70.3   69.8   66.7 1226. ]\n",
      " [  61.5   79.    74.6   76.7   71.4   74.8   74.1   80.7 1480. ]\n",
      " [  73.4   84.6   80.9   87.4   76.9   89.5   72.1   70.2 1781. ]\n",
      " [  42.4   67.7   55.6   63.2   58.8   64.2   53.4   48.8 1234. ]\n",
      " [  81.4   85.6   78.5   87.7   78.7   86.6   75.3   66.  1647. ]\n",
      " [  76.9   83.1   77.5   80.    78.9   82.8   73.5   74.5 1556. ]\n",
      " [  58.2   76.5   69.2   77.6   76.4   80.5   68.9   68.7 1390. ]\n",
      " [  55.    67.2   56.7   55.    63.5   55.6   59.2   59.3 1135. ]\n",
      " [  39.4   68.1   51.8   62.2   61.8   64.9   54.2   40.9 1176. ]\n",
      " [  60.    71.8   61.8   64.8   64.    64.1   58.4   59.  1090. ]\n",
      " [  40.4   69.5   56.4   69.9   65.1   68.8   71.4   53.9 1194. ]\n",
      " [  62.3   64.6   53.4   56.4   63.    62.4   54.5   60.4 1252. ]\n",
      " [  58.8   67.4   50.5   59.1   63.    62.1   56.1   60.6 1188. ]\n",
      " [  53.9   58.7   60.9   54.4   58.    57.4   57.6   52.3 1182. ]\n",
      " [  37.8   67.2   48.3   56.6   66.9   59.5   57.8   62.9 1121. ]\n",
      " [  45.7   65.9   54.5   54.9   63.6   63.8   59.7   68.8 1268. ]\n",
      " [  52.2   72.1   55.3   72.5   69.5   71.7   54.2   69.1 1223. ]\n",
      " [  51.1   68.3   63.1   68.    65.6   73.8   57.    56.5 1214. ]\n",
      " [  43.8   65.5   59.1   54.7   64.4   61.2   60.3   65.2 1314. ]\n",
      " [  53.8   79.4   62.8   68.6   69.5   75.7   52.8   45.  1276. ]\n",
      " [  87.5   92.6   91.8   95.4   93.9   93.4   88.1   88.3 2041. ]\n",
      " [  60.8   73.    68.1   78.7   74.5   71.7   63.6   52.7 1291. ]\n",
      " [  85.4   93.4   86.9   93.2   85.5   94.8   85.4   90.  2013. ]\n",
      " [  47.1   74.6   54.9   64.5   61.3   65.7   55.7   57.8 1255. ]\n",
      " [  56.4   77.2   66.7   68.7   71.8   71.2   62.9   62.4 1407. ]\n",
      " [  55.6   69.9   63.    67.3   66.7   66.4   67.2   68.8 1248. ]\n",
      " [  47.6   63.6   61.8   62.2   60.6   68.7   48.1   61.5 1240. ]\n",
      " [  54.2   61.5   67.9   71.2   61.6   67.8   62.    49.7 1192. ]\n",
      " [  62.4   66.2   67.2   57.5   69.5   59.3   70.3   65.4 1128. ]\n",
      " [  57.2   76.6   66.3   68.2   72.3   67.3   53.1   45.9 1327. ]\n",
      " [  40.2   65.3   61.2   64.7   60.5   68.3   57.1   68.  1182. ]\n",
      " [  82.6   88.5   87.4   91.9   89.8   91.    78.4   80.7 1896. ]\n",
      " [  47.    67.6   55.6   58.1   61.    58.8   60.5   57.2 1216. ]\n",
      " [  58.5   69.8   61.3   75.6   62.7   74.7   69.2   62.2 1435. ]\n",
      " [  55.8   67.5   61.4   61.9   64.4   69.2   62.3   61.4 1334. ]\n",
      " [  33.6   71.7   59.7   64.4   63.9   70.6   54.6   35.9 1188. ]\n",
      " [  62.7   69.2   71.7   70.3   71.7   67.6   70.8   66.9 1313. ]\n",
      " [  67.    90.    74.6   83.2   74.7   83.9   71.1   66.8 1643. ]\n",
      " [  56.1   71.4   64.5   64.8   62.5   70.5   66.1   57.5 1179. ]\n",
      " [  57.5   84.8   69.4   77.7   67.4   76.8   71.    77.  1386. ]\n",
      " [  51.9   69.4   68.    68.9   64.1   69.    54.8   61.1 1099. ]\n",
      " [  69.7   66.5   74.1   69.8   68.9   74.6   73.3   83.  1327. ]\n",
      " [  57.1   73.2   58.5   67.7   68.    75.3   61.4   65.  1360. ]\n",
      " [  67.2   76.2   71.6   70.9   69.5   71.7   72.8   81.1 1420. ]\n",
      " [  73.5   71.    72.2   68.5   73.    77.    69.    73.2 1322. ]\n",
      " [  58.1   67.7   67.3   66.8   63.8   72.9   63.5   80.4 1287. ]\n",
      " [  72.7   50.4   63.2   62.8   62.2   62.2   59.2   57.3 1285. ]\n",
      " [  56.4   78.1   69.8   69.6   62.6   74.1   66.1   71.9 1451. ]\n",
      " [  52.7   62.3   63.7   69.3   68.2   70.1   60.4   58.2 1326. ]\n",
      " [  68.9   79.2   75.6   74.6   70.8   76.1   77.1   76.  1580. ]\n",
      " [  67.3   71.8   69.3   76.8   67.3   69.7   66.1   75.8 1386. ]\n",
      " [  74.    85.1   82.    81.1   64.7   82.8   73.9   76.8 1640. ]\n",
      " [  68.7   79.5   73.6   79.4   72.6   77.    75.9   84.9 1404. ]\n",
      " [  59.7   78.5   58.3   63.5   65.9   68.2   69.    76.3 1313. ]\n",
      " [  71.1   77.6   63.5   73.7   77.4   80.5   70.4   74.1 1277. ]\n",
      " [  49.5   65.7   65.4   64.9   64.5   63.3   65.5   76.6 1224. ]\n",
      " [  56.4   67.4   67.5   60.5   62.8   64.1   59.9   77.  1290. ]\n",
      " [  50.    66.9   60.5   72.7   72.7   72.3   63.6   66.8 1211. ]\n",
      " [  59.9   81.    71.2   81.5   66.    82.4   67.6   66.1 1427. ]\n",
      " [  47.6   70.4   59.7   76.2   70.9   66.1   54.1   54.4 1335. ]\n",
      " [  67.9   79.    77.6   77.8   75.    81.6   71.4   81.7 1431. ]\n",
      " [  55.4   74.1   66.1   64.    66.    69.9   68.6   75.5 1314. ]\n",
      " [  72.3   64.8   70.    57.    64.    64.    60.2   64.7 1256. ]\n",
      " [  90.7   91.9   93.7   95.2   87.2   92.7   87.9   87.1 1981. ]\n",
      " [  67.    60.    78.8   74.4   65.3   75.3   72.1   72.3 1578. ]\n",
      " [  77.8   76.8   82.5   76.8   72.9   80.8   77.6   79.5 1530. ]\n",
      " [  50.    68.2   58.5   58.9   63.7   65.1   71.9   71.2 1184. ]\n",
      " [  62.8   70.6   74.3   70.2   70.6   75.6   64.5   64.2 1487. ]\n",
      " [  61.7   74.6   64.5   69.3   62.4   72.9   67.6   64.2 1326. ]\n",
      " [  56.5   74.4   67.    69.4   70.8   71.3   64.8   68.1 1285. ]\n",
      " [  44.5   69.9   66.3   65.2   64.1   65.4   68.8   65.6 1218. ]\n",
      " [  59.7   67.7   64.2   63.5   66.4   62.2   66.7   61.4 1214. ]\n",
      " [  63.    79.6   72.5   77.2   76.1   79.1   68.6   63.8 1397. ]\n",
      " [  69.1   80.3   75.5   79.1   75.1   78.9   71.4   78.2 1193. ]\n",
      " [  63.5   77.    67.9   68.8   69.8   70.4   69.4   64.4 1410. ]\n",
      " [  73.4   79.3   76.2   75.8   69.1   77.2   70.3   71.6 1485. ]\n",
      " [  58.8   70.3   62.9   67.5   66.4   66.8   60.8   56.7 1306. ]\n",
      " [  77.7   79.4   75.6   73.4   70.    80.6   70.7   75.3 1457. ]\n",
      " [  48.    63.8   56.8   60.1   57.9   62.2   55.    58.7 1248. ]\n",
      " [  43.7   69.5   49.8   58.4   62.7   64.3   55.1   47.2 1253. ]\n",
      " [  52.3   81.9   69.7   77.    71.3   79.1   58.4   41.4 1346. ]\n",
      " [  62.4   66.6   65.2   63.5   69.7   70.    69.4   67.1 1316. ]\n",
      " [  41.2   67.4   54.6   61.9   65.7   63.9   51.9   55.6 1265. ]\n",
      " [  64.5   87.4   75.2   81.6   61.7   84.2   67.3   74.3 1622. ]\n",
      " [  75.1   71.8   77.2   67.2   64.5   75.1   76.3   72.1 1274. ]\n",
      " [  67.    65.6   75.    63.4   72.6   77.1   69.3   79.8 1245. ]\n",
      " [  53.8   85.1   74.    79.5   72.5   81.5   77.2   71.9 1409. ]\n",
      " [  58.1   74.4   66.3   66.9   67.2   72.7   66.7   70.  1344. ]\n",
      " [  57.9   67.9   60.3   59.7   65.4   67.    62.8   67.6 1284. ]\n",
      " [  54.5   71.1   62.    63.1   66.5   67.6   64.4   64.  1355. ]\n",
      " [  61.5   78.7   66.7   71.6   66.6   73.4   63.7   66.2 1446. ]\n",
      " [  62.3   77.7   66.5   71.8   65.4   73.3   68.9   71.7 1473. ]\n",
      " [  52.8   69.8   66.7   60.7   63.5   64.5   61.7   61.1 1141. ]]\n",
      "(109, 9)\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('/Users/Farhad_Ahmed/Desktop/ML intros/ML Project/HS_Regents_Sat_Scores_2015.csv')\n",
    "df = pd.read_csv('HS_Regents_Sat_Scores_2015.csv')\n",
    "#print(df)\n",
    "#data = df.values\n",
    "\n",
    "# extract all the columns that we need\n",
    "df1=np.stack((df['Algebra2/Trigonometry'], df['English'], df['Geometry'],df['Global History and Geography'], df['Integrated Algebra'], df['Living Environment'], df['Physical Settings/Chemistry'], df['Physical Settings/Physics'], df['Average SAT Score (Total)'])).T\n",
    "\n",
    "#remove any empty rows\n",
    "df2=(df1[~np.isnan(df1).any(axis=1)])\n",
    "print(df2)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now splice the dataframe into the feature matrix and target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 8)\n",
      "(109, 1)\n"
     ]
    }
   ],
   "source": [
    "# df3 will be our feature matrix\n",
    "df3 = df2[:,:8]\n",
    "#print(df3)\n",
    "\n",
    "# df4 will be the target vector\n",
    "df4 = df2[:,8:]\n",
    "#print(df4)\n",
    "\n",
    "X = np.array(df3)\n",
    "Y = np.array(df4)\n",
    "\n",
    "# Check the shape of x and y vectors.\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data: Training Set and Test Set K-FOLD \n",
    "\n",
    "To show the original shape of the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the feature matrix and target vector are both partitioned using k-fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree:  1\n",
      "[[1443.84925839]\n",
      " [1326.67203916]\n",
      " [1361.13088347]\n",
      " [1302.61324908]\n",
      " [1302.31034758]\n",
      " [1449.6507148 ]\n",
      " [1418.06792696]\n",
      " [1298.64909127]\n",
      " [1468.11497271]\n",
      " [1497.0632291 ]\n",
      " [1463.33218952]\n",
      " [1429.0138743 ]\n",
      " [1432.39943164]\n",
      " [1432.40524155]\n",
      " [1384.95050953]\n",
      " [1272.57257756]\n",
      " [1395.90504638]\n",
      " [1348.15948241]]\n",
      "Degree:  2\n",
      "[[ 1467.76171875]\n",
      " [ -297.625     ]\n",
      " [ 1025.8671875 ]\n",
      " [ -239.0703125 ]\n",
      " [-3135.03515625]\n",
      " [-1156.14453125]\n",
      " [-1633.1640625 ]\n",
      " [ -743.046875  ]\n",
      " [-2530.04296875]\n",
      " [ 2700.6328125 ]\n",
      " [-2748.09765625]\n",
      " [ 3059.609375  ]\n",
      " [ 1850.93359375]\n",
      " [ 6374.61328125]\n",
      " [ 2287.57421875]\n",
      " [ 4431.8046875 ]\n",
      " [  632.96484375]\n",
      " [ 1200.7109375 ]]\n",
      "Degree:  3\n",
      "[[1358.35813676]\n",
      " [1090.13269084]\n",
      " [ 622.71163412]\n",
      " [ 925.20547815]\n",
      " [-735.45939007]\n",
      " [-155.31502229]\n",
      " [ 356.60008204]\n",
      " [1092.50139311]\n",
      " [2240.63671385]\n",
      " [1817.80221766]\n",
      " [4805.69688943]\n",
      " [1602.71927637]\n",
      " [1098.08135316]\n",
      " [-284.06097413]\n",
      " [1786.1946516 ]\n",
      " [ 916.25499059]\n",
      " [2314.17600113]\n",
      " [1776.86876124]]\n",
      "Degree:  4\n",
      "[[ 1394.42978863]\n",
      " [ 1164.09582347]\n",
      " [  371.30782536]\n",
      " [  997.19797003]\n",
      " [-1055.88447215]\n",
      " [  389.47841132]\n",
      " [  901.98664682]\n",
      " [ 1009.97979112]\n",
      " [ 1311.80390817]\n",
      " [ 1579.03835818]\n",
      " [ 5100.67741084]\n",
      " [ 1393.73986209]\n",
      " [  823.77891041]\n",
      " [ -362.18835059]\n",
      " [ 1858.45961275]\n",
      " [ 1208.56743145]\n",
      " [ 2246.05050769]\n",
      " [ 1764.08216354]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test \n",
    "    \n",
    "\"\"\"\n",
    "scaler = preprocessing.StandardScaler().fit(X_tr)\n",
    "X_train = scaler.transform(X_tr) # zero mean and unit variance\n",
    "X_test = scaler.transform(X_test) # The n later when\n",
    "    \n",
    "scaler = preprocessing.StandardScaler().fit(Y_tr)\n",
    "Y_train = scaler.transform(Y_tr) # zero mean and unit variance\n",
    "Y_test = scaler.transform(Y_test) # The n later when\n",
    "\"\"\"\n",
    "    \n",
    "'''\n",
    "print(X_tr.shape,X_test.shape,Y_tr.shape,Y_test.shape)\n",
    "    \n",
    "plt.scatter(X_tr[:,0],Y_tr,color=\"blue\")\n",
    "plt.xlabel('Training set of X',color=\"blue\")\n",
    "plt.ylabel('Training set of Y',color=\"blue\")\n",
    "plt.show()\n",
    "    \n",
    "plt.scatter(X_test[:,0],Y_test,color=\"green\")\n",
    "plt.xlabel('Testing set of X', color=\"green\")\n",
    "plt.ylabel('Testing set of Y', color=\"green\")\n",
    "plt.show()\n",
    "'''\n",
    "X = X_train\n",
    "vector = Y_train\n",
    "predict= X_test\n",
    "    \n",
    "for d in range(1, 6):\n",
    "    print(\"Degree: \", d)\n",
    "        \n",
    "\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    X_ = poly.fit_transform(X)\n",
    "    predict_ = poly.fit_transform(predict)\n",
    "\n",
    "    clf = linear_model.LinearRegression()\n",
    "    clf.fit(X_, vector)\n",
    "    print(clf.predict(predict_))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Obtain polynomial regression models of different orders starting from linear regression i.e. degree = 1 to higher degree models like degree = 2 to 10. Find training and test error for every order and plot these errors v/s degree. Select the order that fits the data best based on low training and test error. You can use poly.polyval method from numpy to find coefficients of the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree:  1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected 1D vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4bcb28d2da9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Degree: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# polyfit will return array of polynomial coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpolyCoefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Polynomial Coefficients: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolyCoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/polynomial/polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[0;34m(x, y, deg, rcond, full, w)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected deg >= 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 1D vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected non-empty vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected 1D vector for x"
     ]
    }
   ],
   "source": [
    "Errors_test = []\n",
    "Errors_tr = []\n",
    "for degree in range(1, 7):\n",
    "    print(\"Degree: \", degree)\n",
    "    # polyfit will return array of polynomial coefficients \n",
    "    polyCoefficients = poly.polyfit(X_tr, Y_tr, degree)\n",
    "    print(\"Polynomial Coefficients: \", polyCoefficients)\n",
    "    \n",
    "    yHat_tr = poly.polyval(X_tr, polyCoefficients)\n",
    "    TrainingError = np.sum(np.square(Y_tr - yHat_tr)) * 1/(2*Y_tr.shape[0])\n",
    "    Errors_tr.append(TrainingError)\n",
    "    print(\"Training Errors: \", Errors_tr)\n",
    "    \n",
    "    yHat_test  = poly.polyval(X_test, polyCoefficients)\n",
    "    TestError = np.sum(np.square(Y_test - yHat_test)) * 1/(2*Y_test.shape[0])\n",
    "    Errors_test.append(TestError)\n",
    "    print(\"Test Errors: \", Errors_test)\n",
    "    \n",
    "    # creates evenly spaced numbers over a specified interval\n",
    "    xAxisSpacing = np.linspace(-1, 1, 150)\n",
    "    # evaluates the polynomial at all points across the xAxisSpacing\n",
    "    yAxisHat = poly.polyval(xAxisSpacing, polyCoefficients)\n",
    "    plt.xlim(-2,2)\n",
    "    plt.ylim(-25,25)\n",
    "    plt.plot(xAxisSpacing,yAxisHat, 'r-')\n",
    "    plt.scatter(X_tr,Y_tr)\n",
    "    plt.xlabel(\"Training Set of X\")\n",
    "    plt.ylabel(\"Training Set of Y\")\n",
    "    plt.xlim([-2,2])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 8)\n",
      "(87, 1)\n",
      "Degree:  1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected 1D vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ee627c8a2de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Degree: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# polyfit will return array of polynomial coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpolyCoefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Polynomial Coefficients: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolyCoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/polynomial/polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[0;34m(x, y, deg, rcond, full, w)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected deg >= 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 1D vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected non-empty vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected 1D vector for x"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "for train, test in kf.split(X):\n",
    "    \n",
    "    \n",
    "    X_tr, X_test, Y_tr, Y_test = X[train], X[test], Y[train], Y[test]\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X_tr)\n",
    "    X_tr = scaler.transform(X_tr) # zero mean and unit variance\n",
    "    X_test = scaler.transform(X_test) # The n later when\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(Y_tr)\n",
    "    Y_tr = scaler.transform(Y_tr) # zero mean and unit variance\n",
    "    Y_test = scaler.transform(Y_test) # The n later when\n",
    "    \n",
    "    # this is necessary for plotting, might need to undo  later\n",
    "    #print(X_tr.shape,X_test.shape,Y_tr.shape,Y_test.shape)\n",
    "    \n",
    "    #X_tr = np.array(X_tr)\n",
    "    #Y_tr = np.array(Y_tr)\n",
    "    #X_test = np.array(X_test)\n",
    "    #Y_test = np.array(Y_test)\n",
    "    \n",
    "    print(X_tr.shape)\n",
    "    print(Y_tr.shape)\n",
    "    Errors_test = []\n",
    "    Errors_tr = []\n",
    "    \n",
    "    for degree in range(1, 7):\n",
    "        #X is the independent variable (bivariate in this case)\n",
    "        X = X_tr\n",
    "        \n",
    "        #vector is the dependent data\n",
    "        vector = Y_tr\n",
    "\n",
    "        #predict is an independent variable for which we'd like to predict the value\n",
    "        predict= [0.49, 0.18]\n",
    "\n",
    "        #generate a model of polynomial features\n",
    "        poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "        #transform the x data for proper fitting (for single variable type it returns,[1,x,x**2])\n",
    "        X_ = poly.fit_transform(X)\n",
    "\n",
    "        #transform the prediction to fit the model type\n",
    "        predict_ = poly.fit_transform(predict)\n",
    "\n",
    "        #here we can remove polynomial orders we don't want\n",
    "        #for instance I'm removing the `x` component\n",
    "        X_ = np.delete(X_,(1),axis=1)\n",
    "        predict_ = np.delete(predict_,(1),axis=1)\n",
    "\n",
    "        #generate the regression object\n",
    "        clf = linear_model.LinearRegression()\n",
    "        #preform the actual regression\n",
    "        clf.fit(X_, vector)\n",
    "\n",
    "        print(\"X_ = \",X_)\n",
    "        print(\"predict_ = \",predict_)\n",
    "        print(\"Prediction = \",clf.predict(predict_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find training and test error for every order and plot these errors v/s degree. Select the order that fits the data best based on low training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degree = np.array(range(1,11))\n",
    "# Plot the degree against the Training Error\n",
    "plt.plot(degree,Errors_tr)\n",
    "plt.xlabel(\"Degree Order\")\n",
    "plt.ylabel(\"Training Error\")\n",
    "plt.title(\"Training Error vs. Degree Order\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.array(range(1,11))\n",
    "# Plot the degree against the Training Error\n",
    "plt.plot(degree,Errors_test)\n",
    "plt.xlabel(\"Degree Order\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.title(\"test Error vs. Degree Order\")\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
